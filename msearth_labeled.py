# -- coding: utf-8 --
"""
Stage 3 Labeling: Universal DOI Verification
Uses 'doi.org' Content Negotiation to resolve ANY DOI (CrossRef, DataCite, etc.)
"""
import os
import json
import time
import re
import threading
import requests
from argparse import ArgumentParser
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from openai import OpenAI

# ---------------- Configuration ----------------

SYSTEM_PROMPT = """
You are an expert Scientific Citation Verifier.
Your goal is to verify the authenticity of a specific "search tool output" generated by an AI.

**Verification Process:**
1. **Analyze the Claim:** Read the "Target Search Output" (what the AI generated).
2. **Analyze the Evidence:** Read the "DOI Ground Truth" (metadata fetched directly from the DOI system).
3. **Compare:** 
   - If the DOI verification says "DOI Not Found / Invalid", the paper is **Hallucinated**.
   - If the DOI exists but points to a *completely different* paper (different title/author), the result is **Fake_DOI** (DOI Hijacking).
   - If the DOI points to the correct paper, the result is **Authentic**.

**Output Format:**
Return a STRICT JSON object:
{
    "status": "Authentic" | "Hallucinated" | "Inaccurate" | "Unverifiable",
    "issue_type": "None" | "Fake_Paper" | "Fake_DOI" | "Content_Mismatch" | "Other",
    "analysis": "<Explain your reasoning based on the comparison>"
}
"""

USER_PROMPT_TEMPLATE = """
**Target Search Output (The Claim):**
{tool_output}

**DOI Ground Truth (The Reality via DOI.org):**
{doi_check_result}

**Instructions:**
- Compare the title and year in the "Claim" vs the "Ground Truth".
- If the output has a DOI, but the Ground Truth says "Not Found", it is a hallucination.
- Return ONLY the JSON object.
"""

# ---------------- Helpers: Universal DOI Resolver ----------------

def clean_doi_string(doi: str):
    """
    清洗 DOI 字符串，去除常见的尾部标点和空白
    """
    doi = doi.strip()
    # 移除末尾的句号、逗号（LLM 常犯错误）
    doi = doi.rstrip(".,;)]}")
    # 移除开头的 url 前缀（如果 LLM 输出了 https://doi.org/...）
    doi = doi.replace("https://doi.org/", "").replace("http://doi.org/", "")
    return doi

def get_doi_metadata_universal(doi: str):
    """
    方案：使用 doi.org 的 Content Negotiation。
    它可以解析 CrossRef, DataCite, mEDRA 等所有注册机构的 DOI。
    """
    doi = clean_doi_string(doi)
    url = f"https://doi.org/{doi}"
    
    # 核心：这个 Header 告诉 doi.org 返回 JSON 数据而不是跳转网页
    headers = {
        "Accept": "application/vnd.citationstyles.csl+json",
        "User-Agent": "ScientificVerifier/1.0 (mailto:your_email@example.com)" # 替换为你的邮箱，礼貌请求防止被封
    }
    
    try:
        # 设置 timeout，有些冷门 DOI 解析很慢
        resp = requests.get(url, headers=headers, timeout=15, allow_redirects=True)
        
        if resp.status_code == 404:
            return f"Status: DOI Not Found (404). The DOI '{doi}' does not exist."
        
        if resp.status_code != 200:
            return f"Status: Error query ({resp.status_code})."
            
        try:
            data = resp.json()
        except:
            return "Status: Error parsing JSON response from DOI.org."
        
        # 解析标准 CSL-JSON 格式
        real_title = data.get("title", "No Title")
        if isinstance(real_title, list): # 有时 title 是个列表
            real_title = real_title[0] if real_title else "No Title"
            
        # 解析作者
        authors_list = data.get("author", [])
        real_authors = []
        for a in authors_list[:3]: # 只取前3个
            name = f"{a.get('given','')} {a.get('family','')}".strip()
            if not name and 'literal' in a: name = a['literal']
            if name: real_authors.append(name)
        authors_str = ", ".join(real_authors)
        
        # 解析年份
        issued = data.get("issued", {})
        date_parts = issued.get("date-parts", [])
        real_year = date_parts[0][0] if (date_parts and len(date_parts[0]) > 0) else "Unknown Year"
        
        # 解析容器（期刊名/书名）
        container = data.get("container-title", "Unknown Journal")
        
        return (f"Status: VALID DOI.\n"
                f"   - Real Title: {real_title}\n"
                f"   - Real Authors: {authors_str}\n"
                f"   - Real Year: {real_year}\n"
                f"   - Journal/Source: {container}")
                
    except requests.Timeout:
        return "Status: Check Timeout (Network slow)."
    except Exception as e:
        return f"Status: Check Failed (Error: {str(e)})"

def verify_content_validity(text: str):
    """
    提取文本中的 DOI 并查证
    """
    # 简单的 DOI 提取正则
    doi_pattern = r'\b(10\.\d{4,9}/[-._;()/:a-zA-Z0-9]+)\b'
    raw_dois = re.findall(doi_pattern, text)
    
    if not raw_dois:
        return "No DOI detected in the output."
    
    results = []
    checked_dois = set()
    
    for raw_doi in raw_dois:
        clean_doi = clean_doi_string(raw_doi)
        if clean_doi in checked_dois: continue
        
        metadata = get_doi_metadata_universal(clean_doi)
        results.append(f"DOI [{clean_doi}] -> {metadata}")
        checked_dois.add(clean_doi)
    
    return "\n\n".join(results)

# ---------------- Helpers: LLM & Main Loop ----------------
# (这部分和之前一样，为了完整性保留结构，可以直接复用之前的逻辑)

def try_request_with_retries(fn, max_retries=3, delay=2, **kwargs):
    for i in range(max_retries):
        try:
            return fn(**kwargs), None
        except Exception as e:
            if i == max_retries - 1:
                return None, str(e)
            time.sleep(delay * (i + 1))
    return None, "unknown_error"

def extract_json_from_text(text: str):
    if not text: return None
    try:
        m = re.search(r"```json\s*([\s\S]*?)\s*```", text, flags=re.IGNORECASE)
        js_str = m.group(1) if m else text
        js_str = js_str.strip()
        js_str = re.sub(r",\s*([\]}])", r"\1", js_str)
        return json.loads(js_str)
    except:
        try:
            s = text.find("{")
            e = text.rfind("}")
            if s != -1 and e != -1:
                return json.loads(text[s:e+1])
        except:
            pass
        return None

def call_judge_model(client: OpenAI, model: str, tool_output: str, doi_check_result: str):
    user_content = USER_PROMPT_TEMPLATE.format(
        tool_output=tool_output,
        doi_check_result=doi_check_result
    )
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_content},
        ],
        temperature=0.0
    )
    return resp.choices[0].message.content if resp.choices else ""

def verify_single_step_output(client: OpenAI, model: str, step_data: dict):
    output_to_verify = step_data.get("tool_output", "")
    
    if not output_to_verify or len(output_to_verify) < 5 or "none" in output_to_verify.lower():
        return {
            "status": "Unverifiable",
            "issue_type": "No_Content",
            "analysis": "Tool output is empty."
        }

    # 1. 物理查证 (Universal Resolver)
    doi_check_result = verify_content_validity(output_to_verify)

    # 2. 逻辑查证 (LLM)
    raw_response, err = try_request_with_retries(
        call_judge_model,
        client=client,
        model=model,
        tool_output=output_to_verify,
        doi_check_result=doi_check_result
    )

    if err:
        return {"status": "Error", "issue_type": "API_Fail", "analysis": str(err)}

    parsed = extract_json_from_text(raw_response)
    if not parsed:
        return {"status": "Error", "issue_type": "Parse_Fail", "analysis": "JSON Parse Error"}
    
    parsed["doi_ground_truth"] = doi_check_result
    return parsed

def process_one_item(item: dict, client: OpenAI, model: str):
    out = dict(item)
    steps = item.get("generated_answer_parsed", [])
    if not isinstance(steps, list) or not steps:
        out["verify_status"] = "skipped_no_parsed_steps"
        return out

    verified_steps = []
    has_verification = False
    for step in steps:
        new_step = dict(step)
        if str(new_step.get("tool_type", "")).lower() == "web_search":
            new_step["verification_result"] = verify_single_step_output(client, model, new_step)
            has_verification = True
        verified_steps.append(new_step)

    out["generated_answer_parsed"] = verified_steps
    out["verify_status"] = "processed" if has_verification else "skipped"
    return out

def main():
    parser = ArgumentParser()
    parser.add_argument("--input-file", type=str, default="./toolsciverifier/results/msearth_open_search.jsonl")
    parser.add_argument("--output-dir", type=str, required=True)
    parser.add_argument("--ark-api-key", type=str, default=os.environ.get("ARK_API_KEY", "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"))
    parser.add_argument("--ark-base-url", type=str, default="https://ark.cn-beijing.volces.com/api/v3")
    parser.add_argument("--model", type=str, default="doubao-seed-1-8-251228")
    parser.add_argument("--max-workers", type=int, default=8)
    parser.add_argument("--limit", type=int, default=300) # Default to process all
    parser.add_argument("--overwrite", action="store_true")
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input_file):
        print(f"File not found: {args.input_file}")
        return

    client = OpenAI(base_url=args.ark_base_url, api_key=args.ark_api_key)
    output_filename = f"verified_universal_{os.path.basename(args.input_file)}"
    output_path = os.path.join(args.output_dir, output_filename)
    
    # Process Logic ... (Same as previous file reading/writing logic)
    # ... 省略文件读写部分以节省篇幅，与上一版一致 ...
    
    # 简单的单线程测试入口，方便你先跑一条看看效果
    # test_doi = "10.1038/s41586-020-2649-2"
    # print(get_doi_metadata_universal(test_doi))

    # 完整流程执行
    data = []
    with open(args.input_file, "r") as f:
        for line in f:
            if line.strip():
                try: data.append(json.loads(line))
                except: pass
    if args.limit > 0: data = data[:args.limit]

    print(f"Processing {len(data)} items...")
    os.makedirs(args.output_dir, exist_ok=True)
    mode = "w" if args.overwrite else "a"
    
    with open(output_path, mode) as f_out, ThreadPoolExecutor(max_workers=args.max_workers) as ex:
        futures = [ex.submit(process_one_item, item, client, args.model) for item in data]
        for fut in tqdm(as_completed(futures), total=len(futures)):
            try:
                res = fut.result()
                f_out.write(json.dumps(res, ensure_ascii=False) + "\n")
                f_out.flush()
            except Exception as e:
                print(e)

if __name__ == "__main__":
    main()
